\section*{Projects}
\begin{itemize}

\item \begin{project}[https://cse.iitk.ac.in/users/rharish/ugp2]{Improving GANs through Test-Time Constraints}{Jan '19 - Present}{Prof. Vinay Namboodiri and Prof. Chetan Arora}
    \item Pre-trained GANs are fine-tuned during test time using \textit{interactive user input}, inspired by the \href{https://arxiv.org/abs/1609.03552}{iGAN} paper and the paper \href{https://arxiv.org/abs/1811.09796}{Exploiting Test Time Evidence to Improve Predictions of Deep Neural Networks}.
    \item The user provides sketches of edges on a single output of the generator, and a \textit{difference-of-Gaussians} based loss is backpropagated through the generator to fine-tune the generator's weights.
    \item A regularisation term in the loss prevents the weights from deviating away from the originally learned weights.
\end{project}

\item \begin{project}[https://cse.iitk.ac.in/users/rharish/ugp1]{Multi Agent GANs for Image Super Resolution}{Aug '18 - Dec '18}{Prof. Vinay Namboodiri}
    \item A \textit{Multi-agent generalisation} of \href{https://arxiv.org/abs/1609.04802}{SRGAN} inspired by \href{http://openaccess.thecvf.com/content_cvpr_2018/papers_backup/Ghosh_Multi-Agent_Diverse_Generative_CVPR_2018_paper.pdf}{MADGANs} for image super resolution in \textit{TensorFlow}.
    \item Four generators (with shared lower layers) are fed the four corner sections of the input (with a slight overlap), and their outputs are joined (negating the overlap) to get the final high-resolution image.
    \item Each generator has its own discriminator, along with a global discriminator for the final output.
\end{project}

\item \begin{project}[https://github.com/rharish101/CS771-Project]{Higher Order Optimization in Deep Learning}{Sep '18 - Nov '18}{Prof. Piyush Rai, CS771A Course Project}
    \item A survey on the use of \textit{quasi-Newton methods} in deep learning as part of a course.
    \item \href{http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf}{\textit{Hessian-Free optimization}}, \href{https://arxiv.org/abs/1511.01169}{\textit{AdaQN}}, and \href{https://arxiv.org/abs/1311.2115}{\textit{Sum of Functions Optimizer (SFO)}} were surveyed.
    \item Hessian-Free optimization was tested on an MLP against the \textit{Adam} and SGD optimizers in \textit{TensorFlow} on Python.
\end{project}

\item \begin{project}[https://github.com/rharish101/eye-in-the-sky]{7th Inter IIT - Tech Meet (Silver Medal)}{Dec '18}{IIT Kanpur Contingent}
    \item The Eye in the Sky: Semantic segmentation of satellite images using a dataset of only 14 images.
    \item Won \textit{2nd place} using the \href{http://discovery.ucl.ac.uk/10032237/7/David_08270673.pdf}{\textit{P-Net}} architecture, trained on an augmented dataset generated by slicing each image into multiple images and using rotations.
    \item Model hyperparameters were tuned using the \href{https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization}{\textit{Tree of Parzen Estimators}} method from the \href{https://hyperopt.github.io/hyperopt/}{\textit{Hyperopt}} library.
\end{project}

\item \begin{project}[https://github.com/rharish101/CS335A]{Compiler for Golang in Python}{Jan '19 - April '19}{Prof. Amey Karkare, CS335A Course Project}
    \item A compiler for translating Golang to MIPS written in Python as part of a course.
    \item Basic C-like features like datatypes, variables, expressions, control statements (if-else, switch, loops), arrays, functions, pointers, structs, library imports, and I/O implemented.
    \item Advanced features like composite literals, struct embeddings, typedefs/aliases, operator overloading, multiple value returns, multiple parallel assignments, short declarations, and short-circuit evaluation also implemented.
\end{project}

\item \begin{project}{6th Inter IIT - Tech Meet}{Dec '17 - Jan '18}{IIT Kanpur Contingent}
    \item Fiducial Localisation in Medical Images (\href{https://github.com/rharish101/Fiducial}{https://github.com/rharish101/Fiducial}): Used \textit{Shi-Tomasi} algorithm to identify corners of fiducials after canny-edge detection, followed by \textit{Hough transform} to capture circular faces.
    \item Exoplanet Detection (\href{https://github.com/rharish101/Exoplanet}{https://github.com/rharish101/Exoplanet}): Implemented LSTMs combined with anomaly detection by fitting a beta distribution for a skewed dataset of sequences of light intensities of planets.
\end{project}

\item \begin{project}[https://github.com/rharish101/ACA-Project]{Reinforcement Learning in Atari Games}{Jan '17 - Jul '17}{Association of Computing Activities, IIT Kanpur}
    \item Used \textit{Dynamic Programming} techniques for policy iteration and value iteration to solve a Model-based Markov Decision Process(MDP) in Python using \href{https://gym.openai.com/}{OpenAI Gym} environments.
    \item Implemented on-policy and off-policy \textit{Monte Carlo} control, \textit{SARSA}, \textit{Q-Learning} Temporal Difference control and \textit{DQNs} to solve Model-free MDPs.
    \item Wrote programs to learn playing Atari Pong using both Policy Gradients (using experience replay and fixed targets with an actor-critic using TD learning) and DQNs separately.
\end{project}

\item \begin{project}[https://github.com/rharish101/PClub-Project]{Depression Therapy Chatbot}{May '17 - Jul '17}{Programming Club, IIT Kanpur}
    \item Used a \textit{Word2Vec} model to create a \textit{Sentiment Analysis} model in Python using a Dual LSTM encoder in Keras.
    \item Implemented a chatbot using manually-created responses dependent on sentiment classification.
    \item Used the \href{https://heroku.com}{Heroku} platform to host the bot and integrated it with Facebook Messenger in Python.
\end{project}

\item \begin{project}[https://github.com/DEVANSH99/Image\_cptning2018]{Visual Attention in Image Captioning (Mentored)}{May '18 - Jul '18}{Programming Club, IIT Kanpur}
    \item \textit{Mentored} a team of 3 students in creating an image-captioning framework based on \href{https://arxiv.org/abs/1502.03044}{\it Visual Attention}.
    \item Soft-attention is used along with an LSTM decoder on features obtained through a VGG16 encoder.
\end{project}

\item \begin{project}[https://github.com/rharish101/DLGeneralization]{Generalisation of Deep Learning Networks}{}{}
    \item Self project to recreate the results of the paper \href{https://arxiv.org/abs/1611.03530}{Understanding Deep Learning Requires Rethinking Generalization}.
    \item Implemented mini Inception, mini Alexnet and two different MLPs to classify images on CIFAR10, with and without regularisation, and with random labels.
\end{project}

\end{itemize}
